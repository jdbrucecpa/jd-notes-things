import { app, BrowserWindow, ipcMain } from 'electron';
import * as dotenv from 'dotenv';
import { IPCChannel, RecordingSession, Transcript, TranscriptSegment, Participant } from '../shared/types';
import { RecordingManager } from './recording/RecordingManager';
import { TranscriptionService } from './transcription/TranscriptionService';
import { FileManager } from './storage/FileManager';
import { DEFAULT_TRANSCRIPTION_PROVIDER } from '../shared/constants';

// Load environment variables
dotenv.config();

// This allows TypeScript to pick up the magic constants that's auto-generated by Forge's Webpack
// plugin that tells the Electron app where to look for the Webpack-bundled app code (depending on
// whether you're running in development or production).
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) {
  app.quit();
}

// Global state
let mainWindow: BrowserWindow | null = null;

// Services
let recordingManager: RecordingManager;
let transcriptionService: TranscriptionService;
let fileManager: FileManager;

// Initialize services
function initializeServices() {
  console.log('[Main] Initializing services...');

  // Recording Manager
  recordingManager = new RecordingManager({
    recallApiKey: process.env.RECALLAI_API_KEY,
    recallApiUrl: process.env.RECALLAI_API_URL,
    assemblyAiApiKey: process.env.ASSEMBLYAI_API_KEY,
  });

  // Transcription Service
  transcriptionService = new TranscriptionService(
    (process.env.TRANSCRIPTION_PROVIDER as any) || DEFAULT_TRANSCRIPTION_PROVIDER,
    {
      apiKey: process.env.ASSEMBLYAI_API_KEY,
    }
  );

  // File Manager
  fileManager = new FileManager('./'); // Save to current directory for Phase 1

  console.log('[Main] Services initialized');
  console.log('[Main] Transcription provider:', transcriptionService.getProviderInfo());
}

const createWindow = (): void => {
  // Create the browser window.
  mainWindow = new BrowserWindow({
    height: 600,
    width: 800,
    webPreferences: {
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY,
      contextIsolation: true,
      nodeIntegration: false,
    },
  });

  // and load the index.html of the app.
  mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY);

  // Open the DevTools.
  mainWindow.webContents.openDevTools();

  mainWindow.on('closed', () => {
    mainWindow = null;
  });
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on('ready', () => {
  initializeServices();
  createWindow();
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.

// ============================================================================
// IPC Handlers
// ============================================================================

/**
 * Handle start recording request from renderer
 */
ipcMain.handle(IPCChannel.START_RECORDING, async () => {
  try {
    console.log('[Main] Start recording requested');

    // Start recording using RecordingManager
    const session = await recordingManager.startRecording();

    // Notify renderer that recording started
    if (mainWindow) {
      mainWindow.webContents.send(IPCChannel.RECORDING_STARTED, session);
    }

    return { success: true, session };
  } catch (error: any) {
    console.error('[Main] Error starting recording:', error);
    if (mainWindow) {
      mainWindow.webContents.send(IPCChannel.RECORDING_ERROR, error.message);
    }
    return { success: false, error: error.message };
  }
});

/**
 * Handle stop recording request from renderer
 */
ipcMain.handle(IPCChannel.STOP_RECORDING, async () => {
  try {
    console.log('[Main] Stop recording requested');

    // Stop recording using RecordingManager
    const session = await recordingManager.stopRecording();

    // Notify renderer that recording stopped
    if (mainWindow) {
      mainWindow.webContents.send(IPCChannel.RECORDING_STOPPED, session);
    }

    // Process asynchronously (don't block the UI)
    processRecording(session).catch(error => {
      console.error('[Main] Error processing recording:', error);
      if (mainWindow) {
        mainWindow.webContents.send(IPCChannel.TRANSCRIPTION_ERROR, error.message);
      }
    });

    return { success: true, session };
  } catch (error: any) {
    console.error('[Main] Error stopping recording:', error);
    if (mainWindow) {
      mainWindow.webContents.send(IPCChannel.RECORDING_ERROR, error.message);
    }
    return { success: false, error: error.message };
  }
});

/**
 * Process recording: get transcript from Recall.ai (via AssemblyAI) and save
 */
async function processRecording(session: RecordingSession): Promise<void> {
  try {
    console.log('[Main] Processing recording:', session.id);

    // Get transcript from Recall.ai (which used AssemblyAI for transcription)
    console.log('[Main] Fetching transcript from Recall.ai...');
    const recallTranscript = await recordingManager.getTranscript();

    // Convert Recall.ai transcript to our internal format
    const transcript: Transcript = convertRecallTranscriptToInternal(recallTranscript, session);

    // Save transcript
    console.log('[Main] Saving transcript...');
    const transcriptPath = await fileManager.saveTranscript(transcript);

    console.log('[Main] Processing complete. Transcript saved to:', transcriptPath);

    // Notify renderer
    if (mainWindow) {
      mainWindow.webContents.send(IPCChannel.TRANSCRIPTION_COMPLETE, {
        transcript,
        transcriptPath,
      });
    }
  } catch (error: any) {
    console.error('[Main] Processing error:', error);
    throw error;
  }
}

/**
 * Convert Recall.ai transcript format to our internal format
 */
function convertRecallTranscriptToInternal(recallTranscript: any, session: RecordingSession): Transcript {
  const segments: TranscriptSegment[] = [];
  const speakerMap = new Map<string, Participant>();

  console.log('[Main] Converting transcript with', recallTranscript.utterances?.length || 0, 'utterances');

  // Process utterances (speaker-labeled segments from Recall.ai)
  if (recallTranscript.utterances && recallTranscript.utterances.length > 0) {
    for (const utterance of recallTranscript.utterances) {
      const speakerLabel = utterance.speaker || 'Unknown';

      // Create participant if not exists
      if (!speakerMap.has(speakerLabel)) {
        speakerMap.set(speakerLabel, {
          name: `Speaker ${speakerLabel}`,
        });
      }

      // Extract start time - handle both Recall.ai formats
      const startTime = utterance.start_timestamp?.relative ?? utterance.start ?? 0;

      // Add segment
      segments.push({
        speaker: `Speaker ${speakerLabel}`,
        text: utterance.text,
        timestamp: new Date(session.startTime!.getTime() + startTime * 1000), // Convert to absolute timestamp
        confidence: utterance.confidence,
      });
    }
  }

  // If no utterances, try processing words (fall back to word-level if no speaker diarization)
  if (segments.length === 0 && recallTranscript.words && recallTranscript.words.length > 0) {
    console.log('[Main] No utterances found, processing', recallTranscript.words.length, 'words');

    // Group words into sentences (simple approach: every 10 words or period)
    let currentText = '';
    let currentStartTime = 0;

    for (let i = 0; i < recallTranscript.words.length; i++) {
      const word = recallTranscript.words[i];
      const wordText = word.text || '';
      const wordStart = word.start_timestamp?.relative ?? word.start ?? 0;

      if (currentText === '') {
        currentStartTime = wordStart;
      }

      currentText += (currentText ? ' ' : '') + wordText;

      // End segment on period or every 20 words
      if (wordText.endsWith('.') || wordText.endsWith('?') || wordText.endsWith('!') || (i + 1) % 20 === 0) {
        segments.push({
          speaker: 'Speaker 1',
          text: currentText,
          timestamp: new Date(session.startTime!.getTime() + currentStartTime * 1000),
          confidence: word.confidence,
        });
        currentText = '';
      }
    }

    // Add any remaining text
    if (currentText) {
      segments.push({
        speaker: 'Speaker 1',
        text: currentText,
        timestamp: new Date(session.startTime!.getTime() + currentStartTime * 1000),
      });
    }

    speakerMap.set('1', { name: 'Speaker 1' });
  }

  // Calculate duration
  const duration = session.endTime && session.startTime
    ? (session.endTime.getTime() - session.startTime.getTime()) / 1000
    : 0;

  console.log('[Main] Created', segments.length, 'segments from transcript');

  return {
    sessionId: session.id,
    segments,
    metadata: {
      duration,
      participants: Array.from(speakerMap.values()),
      meetingTitle: session.meetingTitle,
      platform: session.platform || 'manual',
    },
  };
}

/**
 * Handle pause recording request from renderer
 */
ipcMain.handle(IPCChannel.PAUSE_RECORDING, async () => {
  try {
    console.log('[Main] Pause recording requested');

    const session = await recordingManager.pauseRecording();

    return { success: true, session };
  } catch (error: any) {
    console.error('[Main] Error pausing recording:', error);
    return { success: false, error: error.message };
  }
});

/**
 * Handle resume recording request from renderer
 */
ipcMain.handle(IPCChannel.RESUME_RECORDING, async () => {
  try {
    console.log('[Main] Resume recording requested');

    const session = await recordingManager.resumeRecording();

    return { success: true, session };
  } catch (error: any) {
    console.error('[Main] Error resuming recording:', error);
    return { success: false, error: error.message };
  }
});

console.log('[Main] IPC handlers registered');
